{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Subreddit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The hosts of the My Favorite Murder podcast would like to know if itâ€™s possible to predict if a piece of content was posted on the True Crime subreddit or on their subreddit. Natural Language Processing was used to convert the text to numeric values, then the data was tested on three model types: Logistic Regression, Naive Bayes, and Support Vector Machine. Success was measured by accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Imports](#Imports)\n",
    "- [Webscraping](#Webscraping)\n",
    "- [EDA](#EDA)\n",
    "  * [DataFrame Creation](#DataFrame-Creation)\n",
    "  * [Comment Counts Review](#Comment-Counts-Review)  \n",
    "  * [Most Popular Words](#Most-Popular-Words)\n",
    "- [Data Cleanup](#Data-Cleanup)\n",
    "  * [Beautiful Soup, Regex, Lemmatizing, and Stopwords](#Beautiful-Soup,-Regex,-Lemmatizing,-and-Stopwords)\n",
    "- [Modeling](#Modeling)\n",
    "  * [Preprocessing](#Preprocessing)\n",
    "  * [Naive Bayes Model](#Naive-Bayes-Model) \n",
    "- [Evaluation](#Evaluation)\n",
    "  * [Confustion Matrix](#Confustion-Matrix) \n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Importing in packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing in the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import regex as re\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from bs4 import BeautifulSoup   \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing warning to turn off future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping\n",
    "\n",
    "Scraping in the data from the subreddits, True Crime and My Favorite Murder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edited code from Boom:\n",
    "#defining urls I'll be pulling from as well as username\n",
    "url_truecrime = \"https://www.reddit.com/r/TrueCrime.json\"\n",
    "url_ssdgm = \"https://www.reddit.com/r/myfavoritemurder.json\"\n",
    "username = {\"User-agent\": 'greybon'}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edited code from Boom:\n",
    "#creating a fuction to pull posts from reddit\n",
    "def get_subreddit(url, n_pulls, headers):   \n",
    "    # Create empty templates\n",
    "    posts = []\n",
    "    after = None\n",
    "\n",
    "    # Create a loop that does max 25 requests per pull\n",
    "    for pull_num in range(n_pulls):\n",
    "        print(\"Pulling data attempted\", pull_num+1,\"time(s)\")\n",
    "\n",
    "        if after == None:\n",
    "            new_url = url                 \n",
    "        else:\n",
    "            new_url = url+\"?after=\"+after \n",
    "\n",
    "        res = requests.get(new_url, headers=headers)\n",
    "\n",
    "        if res.status_code == 200:\n",
    "            subreddit_json = res.json()                      \n",
    "            posts.extend(subreddit_json['data']['children']) \n",
    "            after = subreddit_json['data']['after']          \n",
    "        else:\n",
    "            print(\"We've run into an error. The status code is:\", res.status_code)\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    print(\"We have:\", len(set([p['data']['name'] for p in posts])), \"posts in this subreddit\")\n",
    "        \n",
    "        \n",
    "    return(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1771,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data attempted 1 time(s)\n",
      "Pulling data attempted 2 time(s)\n",
      "Pulling data attempted 3 time(s)\n",
      "Pulling data attempted 4 time(s)\n",
      "Pulling data attempted 5 time(s)\n",
      "Pulling data attempted 6 time(s)\n",
      "Pulling data attempted 7 time(s)\n",
      "Pulling data attempted 8 time(s)\n",
      "Pulling data attempted 9 time(s)\n",
      "Pulling data attempted 10 time(s)\n",
      "Pulling data attempted 11 time(s)\n",
      "Pulling data attempted 12 time(s)\n",
      "Pulling data attempted 13 time(s)\n",
      "Pulling data attempted 14 time(s)\n",
      "Pulling data attempted 15 time(s)\n",
      "Pulling data attempted 16 time(s)\n",
      "Pulling data attempted 17 time(s)\n",
      "Pulling data attempted 18 time(s)\n",
      "Pulling data attempted 19 time(s)\n",
      "Pulling data attempted 20 time(s)\n",
      "Pulling data attempted 21 time(s)\n",
      "Pulling data attempted 22 time(s)\n",
      "Pulling data attempted 23 time(s)\n",
      "Pulling data attempted 24 time(s)\n",
      "Pulling data attempted 25 time(s)\n",
      "Pulling data attempted 26 time(s)\n",
      "Pulling data attempted 27 time(s)\n",
      "Pulling data attempted 28 time(s)\n",
      "Pulling data attempted 29 time(s)\n",
      "Pulling data attempted 30 time(s)\n",
      "Pulling data attempted 31 time(s)\n",
      "Pulling data attempted 32 time(s)\n",
      "Pulling data attempted 33 time(s)\n",
      "Pulling data attempted 34 time(s)\n",
      "Pulling data attempted 35 time(s)\n",
      "Pulling data attempted 36 time(s)\n",
      "Pulling data attempted 37 time(s)\n",
      "Pulling data attempted 38 time(s)\n",
      "Pulling data attempted 39 time(s)\n",
      "Pulling data attempted 40 time(s)\n",
      "We have: 931 posts in this subreddit\n"
     ]
    }
   ],
   "source": [
    "#edited code from Boom:\n",
    "#calling function for true crime subreddit \n",
    "true_crime = get_subreddit(url_truecrime, n_pulls = 40, headers = username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data attempted 1 time(s)\n",
      "Pulling data attempted 2 time(s)\n",
      "Pulling data attempted 3 time(s)\n",
      "Pulling data attempted 4 time(s)\n",
      "Pulling data attempted 5 time(s)\n",
      "Pulling data attempted 6 time(s)\n",
      "Pulling data attempted 7 time(s)\n",
      "Pulling data attempted 8 time(s)\n",
      "Pulling data attempted 9 time(s)\n",
      "Pulling data attempted 10 time(s)\n",
      "Pulling data attempted 11 time(s)\n",
      "Pulling data attempted 12 time(s)\n",
      "Pulling data attempted 13 time(s)\n",
      "Pulling data attempted 14 time(s)\n",
      "Pulling data attempted 15 time(s)\n",
      "Pulling data attempted 16 time(s)\n",
      "Pulling data attempted 17 time(s)\n",
      "Pulling data attempted 18 time(s)\n",
      "Pulling data attempted 19 time(s)\n",
      "Pulling data attempted 20 time(s)\n",
      "Pulling data attempted 21 time(s)\n",
      "Pulling data attempted 22 time(s)\n",
      "Pulling data attempted 23 time(s)\n",
      "Pulling data attempted 24 time(s)\n",
      "Pulling data attempted 25 time(s)\n",
      "Pulling data attempted 26 time(s)\n",
      "Pulling data attempted 27 time(s)\n",
      "Pulling data attempted 28 time(s)\n",
      "Pulling data attempted 29 time(s)\n",
      "Pulling data attempted 30 time(s)\n",
      "Pulling data attempted 31 time(s)\n",
      "Pulling data attempted 32 time(s)\n",
      "Pulling data attempted 33 time(s)\n",
      "Pulling data attempted 34 time(s)\n",
      "Pulling data attempted 35 time(s)\n",
      "Pulling data attempted 36 time(s)\n",
      "Pulling data attempted 37 time(s)\n",
      "Pulling data attempted 38 time(s)\n",
      "Pulling data attempted 39 time(s)\n",
      "Pulling data attempted 40 time(s)\n",
      "We have: 1001 posts in this subreddit\n"
     ]
    }
   ],
   "source": [
    "#edited code from Boom:\n",
    "#calling function for true crime subreddit\n",
    "fav_murder = get_subreddit(url_ssdgm, n_pulls = 40, headers = username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "For EDA, the first thing I did was check out what info was available for each post from each subreddit. Things that are popping out are me are that each post is tagged for what subreddit it belongs to, and that the text available is limited to title, selfttext, and selftexthtml.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 't3',\n",
       " 'data': {'approved_at_utc': None,\n",
       "  'subreddit': 'TrueCrime',\n",
       "  'selftext': 'In an effort to clear up some of the clutter and to maintain the focus of the sub on learning about and discussing True Crime, we have decided to sticky this thread for all lighthearted discussion and memes. Any posts containing memes or jokes outside of this thread will be removed.\\n\\nPlease remember to keep things respectful of victims and their families, any inappropriate content will not be permitted. \\n\\nEnjoy!',\n",
       "  'author_fullname': 't2_j3bh3',\n",
       "  'saved': False,\n",
       "  'mod_reason_title': None,\n",
       "  'gilded': 0,\n",
       "  'clicked': False,\n",
       "  'title': '[Meme Thread] For all jokes and lighthearted discussion',\n",
       "  'link_flair_richtext': [],\n",
       "  'subreddit_name_prefixed': 'r/TrueCrime',\n",
       "  'hidden': False,\n",
       "  'pwls': 6,\n",
       "  'link_flair_css_class': None,\n",
       "  'downs': 0,\n",
       "  'thumbnail_height': None,\n",
       "  'hide_score': False,\n",
       "  'name': 't3_aptilw',\n",
       "  'quarantine': False,\n",
       "  'link_flair_text_color': 'dark',\n",
       "  'author_flair_background_color': None,\n",
       "  'subreddit_type': 'public',\n",
       "  'ups': 47,\n",
       "  'domain': 'self.TrueCrime',\n",
       "  'media_embed': {},\n",
       "  'thumbnail_width': None,\n",
       "  'author_flair_template_id': None,\n",
       "  'is_original_content': False,\n",
       "  'user_reports': [],\n",
       "  'secure_media': None,\n",
       "  'is_reddit_media_domain': False,\n",
       "  'is_meta': False,\n",
       "  'category': None,\n",
       "  'secure_media_embed': {},\n",
       "  'link_flair_text': None,\n",
       "  'can_mod_post': False,\n",
       "  'score': 47,\n",
       "  'approved_by': None,\n",
       "  'thumbnail': 'self',\n",
       "  'edited': False,\n",
       "  'author_flair_css_class': None,\n",
       "  'author_flair_richtext': [],\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'content_categories': None,\n",
       "  'is_self': True,\n",
       "  'mod_note': None,\n",
       "  'created': 1549979420.0,\n",
       "  'link_flair_type': 'text',\n",
       "  'wls': 6,\n",
       "  'banned_by': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'contest_mode': False,\n",
       "  'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In an effort to clear up some of the clutter and to maintain the focus of the sub on learning about and discussing True Crime, we have decided to sticky this thread for all lighthearted discussion and memes. Any posts containing memes or jokes outside of this thread will be removed.&lt;/p&gt;\\n\\n&lt;p&gt;Please remember to keep things respectful of victims and their families, any inappropriate content will not be permitted. &lt;/p&gt;\\n\\n&lt;p&gt;Enjoy!&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "  'likes': None,\n",
       "  'suggested_sort': None,\n",
       "  'banned_at_utc': None,\n",
       "  'view_count': None,\n",
       "  'archived': False,\n",
       "  'no_follow': False,\n",
       "  'is_crosspostable': False,\n",
       "  'pinned': False,\n",
       "  'over_18': False,\n",
       "  'media_only': False,\n",
       "  'can_gild': False,\n",
       "  'spoiler': False,\n",
       "  'locked': False,\n",
       "  'author_flair_text': None,\n",
       "  'visited': False,\n",
       "  'num_reports': None,\n",
       "  'distinguished': 'moderator',\n",
       "  'subreddit_id': 't5_2s5e8',\n",
       "  'mod_reason_by': None,\n",
       "  'removal_reason': None,\n",
       "  'link_flair_background_color': '',\n",
       "  'id': 'aptilw',\n",
       "  'is_robot_indexable': True,\n",
       "  'report_reasons': None,\n",
       "  'author': 'Alicricity',\n",
       "  'num_crossposts': 1,\n",
       "  'num_comments': 14,\n",
       "  'send_replies': True,\n",
       "  'whitelist_status': 'all_ads',\n",
       "  'mod_reports': [],\n",
       "  'author_patreon_flair': False,\n",
       "  'author_flair_text_color': None,\n",
       "  'permalink': '/r/TrueCrime/comments/aptilw/meme_thread_for_all_jokes_and_lighthearted/',\n",
       "  'parent_whitelist_status': 'all_ads',\n",
       "  'stickied': True,\n",
       "  'url': 'https://www.reddit.com/r/TrueCrime/comments/aptilw/meme_thread_for_all_jokes_and_lighthearted/',\n",
       "  'subreddit_subscribers': 97602,\n",
       "  'created_utc': 1549979420.0,\n",
       "  'media': None,\n",
       "  'is_video': False}}"
      ]
     },
     "execution_count": 1773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at the first post to see the breakdown components of a post\n",
    "true_crime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 't3',\n",
       " 'data': {'approved_at_utc': None,\n",
       "  'subreddit': 'myfavoritemurder',\n",
       "  'selftext': \"Just a friendly reminder that we do not allow any direct links to merchandise here on the subreddit.  You are more than welcome to post a picture of it but under no circumstance are you allowed to link to the actual merchandise's website/etsy/etc.\\n\\n\",\n",
       "  'author_fullname': 't2_r4538',\n",
       "  'saved': False,\n",
       "  'mod_reason_title': None,\n",
       "  'gilded': 0,\n",
       "  'clicked': False,\n",
       "  'title': 'New Subscribers: Please Read the Subreddit Rules and reminder: NO MERCHANDISE DIRECT LINKS!',\n",
       "  'link_flair_richtext': [],\n",
       "  'subreddit_name_prefixed': 'r/myfavoritemurder',\n",
       "  'hidden': False,\n",
       "  'pwls': 6,\n",
       "  'link_flair_css_class': None,\n",
       "  'downs': 0,\n",
       "  'thumbnail_height': None,\n",
       "  'hide_score': False,\n",
       "  'name': 't3_9gkh9q',\n",
       "  'quarantine': False,\n",
       "  'link_flair_text_color': 'dark',\n",
       "  'author_flair_background_color': '',\n",
       "  'subreddit_type': 'public',\n",
       "  'ups': 60,\n",
       "  'domain': 'self.myfavoritemurder',\n",
       "  'media_embed': {},\n",
       "  'thumbnail_width': None,\n",
       "  'author_flair_template_id': '8b4c474c-ecc3-11e7-9a1e-0e318977ae68',\n",
       "  'is_original_content': False,\n",
       "  'user_reports': [],\n",
       "  'secure_media': None,\n",
       "  'is_reddit_media_domain': False,\n",
       "  'is_meta': False,\n",
       "  'category': None,\n",
       "  'secure_media_embed': {},\n",
       "  'link_flair_text': None,\n",
       "  'can_mod_post': False,\n",
       "  'score': 60,\n",
       "  'approved_by': None,\n",
       "  'thumbnail': 'self',\n",
       "  'edited': False,\n",
       "  'author_flair_css_class': 'karen',\n",
       "  'author_flair_richtext': [],\n",
       "  'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       "  'content_categories': None,\n",
       "  'is_self': True,\n",
       "  'mod_note': None,\n",
       "  'created': 1537192324.0,\n",
       "  'link_flair_type': 'text',\n",
       "  'wls': 6,\n",
       "  'banned_by': None,\n",
       "  'author_flair_type': 'text',\n",
       "  'contest_mode': False,\n",
       "  'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just a friendly reminder that we do not allow any direct links to merchandise here on the subreddit.  You are more than welcome to post a picture of it but under no circumstance are you allowed to link to the actual merchandise&amp;#39;s website/etsy/etc.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "  'likes': None,\n",
       "  'suggested_sort': 'confidence',\n",
       "  'banned_at_utc': None,\n",
       "  'view_count': None,\n",
       "  'archived': True,\n",
       "  'no_follow': False,\n",
       "  'is_crosspostable': False,\n",
       "  'pinned': False,\n",
       "  'over_18': False,\n",
       "  'media_only': False,\n",
       "  'can_gild': False,\n",
       "  'spoiler': False,\n",
       "  'locked': False,\n",
       "  'author_flair_text': \"I'm a Karen\",\n",
       "  'visited': False,\n",
       "  'num_reports': None,\n",
       "  'distinguished': 'moderator',\n",
       "  'subreddit_id': 't5_3ei8g',\n",
       "  'mod_reason_by': None,\n",
       "  'removal_reason': None,\n",
       "  'link_flair_background_color': '',\n",
       "  'id': '9gkh9q',\n",
       "  'is_robot_indexable': True,\n",
       "  'report_reasons': None,\n",
       "  'author': 'TinaBelcher4Prez',\n",
       "  'num_crossposts': 0,\n",
       "  'num_comments': 20,\n",
       "  'send_replies': True,\n",
       "  'whitelist_status': 'all_ads',\n",
       "  'mod_reports': [],\n",
       "  'author_patreon_flair': False,\n",
       "  'author_flair_text_color': 'dark',\n",
       "  'permalink': '/r/myfavoritemurder/comments/9gkh9q/new_subscribers_please_read_the_subreddit_rules/',\n",
       "  'parent_whitelist_status': 'all_ads',\n",
       "  'stickied': True,\n",
       "  'url': 'https://www.reddit.com/r/myfavoritemurder/comments/9gkh9q/new_subscribers_please_read_the_subreddit_rules/',\n",
       "  'subreddit_subscribers': 67800,\n",
       "  'created_utc': 1537192324.0,\n",
       "  'media': None,\n",
       "  'is_video': False}}"
      ]
     },
     "execution_count": 1774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking out the ssdgm subreddit to see how the posts are broken down too also noting the flair \n",
    "#section marking someone as \"I'm a Karen\". That sort of flag would mark it 100% to this thread \n",
    "#so I'll not use that for prediction purposes.\n",
    "fav_murder[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Creation\n",
    "\n",
    "I created a function to pull elements from the scraped data and put it into a dataframe. I used a dictionary because each section label looked like a good key to add a value to. I pulled in the number of comments because I wanted to see how chatty the audiences are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1775,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to pull in title, selftext, subreddit, and comments info into a dataframe so I'm going to create \n",
    "#a function to do this\n",
    "def pulling_posts(gimme_posts):\n",
    "    \n",
    "#creating an empty df\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    #looping through posts\n",
    "    for post in gimme_posts:\n",
    "        \n",
    "        #creating a dictionary of the pieces I want to pull\n",
    "        content_dict = {'title': [post['data']['title']],\n",
    "                    'selftext': [post['data']['selftext']],\n",
    "                    'subreddit': [post['data']['subreddit']],\n",
    "                    'num_comments': [post['data']['num_comments']]} #pulled in so I can see how chatty\n",
    "                                                                    #the users are, gives a picture of how\n",
    "                                                                    #actively engaged the audiences are\n",
    "        \n",
    "        #appending to the df\n",
    "        to_append = pd.DataFrame(content_dict)\n",
    "        df = df.append(to_append, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1776,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the true crime df\n",
    "true_crime_df = pulling_posts(gimme_posts = true_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1777,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the file so I can read it in and use it from here\n",
    "true_crime_df.to_csv(\"./datasets/true_crime_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the ssdgm df\n",
    "fav_murder_df = pulling_posts(gimme_posts = fav_murder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the file so I can read it in and use it from here\n",
    "fav_murder_df.to_csv(\"./datasets/fav_murder_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1864,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the true crime file\n",
    "true_crime_df = pd.read_csv('./datasets/true_crime_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Meme Thread] For all jokes and lighthearted d...</td>\n",
       "      <td>In an effort to clear up some of the clutter a...</td>\n",
       "      <td>TrueCrime</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A black man in Colorado was detained by cops a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TrueCrime</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  [Meme Thread] For all jokes and lighthearted d...   \n",
       "1  A black man in Colorado was detained by cops a...   \n",
       "\n",
       "                                            selftext  subreddit  num_comments  \n",
       "0  In an effort to clear up some of the clutter a...  TrueCrime            14  \n",
       "1                                                NaN  TrueCrime            30  "
      ]
     },
     "execution_count": 1866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirming that it pulled in what I wanted. Noting that not all posts include selftext\n",
    "#because of that, I won't use it by itself as a predictor\n",
    "true_crime_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The file now has NaNs in it. I'm coverting them to a stopword that will get removed in an upcoming function\n",
    "#that way it won't interfere with anything\n",
    "true_crime_df['selftext'] = true_crime_df['selftext'].fillna('was')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the my favorite murder file\n",
    "fav_murder_df = pd.read_csv('./datasets/fav_murder_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Subscribers: Please Read the Subreddit Rul...</td>\n",
       "      <td>Just a friendly reminder that we do not allow ...</td>\n",
       "      <td>myfavoritemurder</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MFM #167 - Bomb Grade: Official Discussion Post</td>\n",
       "      <td>This is the official discussion post for My Fa...</td>\n",
       "      <td>myfavoritemurder</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  New Subscribers: Please Read the Subreddit Rul...   \n",
       "1    MFM #167 - Bomb Grade: Official Discussion Post   \n",
       "\n",
       "                                            selftext         subreddit  \\\n",
       "0  Just a friendly reminder that we do not allow ...  myfavoritemurder   \n",
       "1  This is the official discussion post for My Fa...  myfavoritemurder   \n",
       "\n",
       "   num_comments  \n",
       "0            20  \n",
       "1            37  "
      ]
     },
     "execution_count": 1869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking out the df, same note on selftext here as for the true crime subreddit, also MFM is mentioned right away.\n",
    "#guessing that may be something that helps in prediction on this just because it references the podcast.\n",
    "fav_murder_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing the same thing I did for the true crime df by changing NaNs to one of the stopwords\n",
    "fav_murder_df['selftext'] = fav_murder_df['selftext'].fillna('was')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that my options for text here are title and selftext. Selftext is not available for all rows, but I'd like to use it. So I'm creating a column for it + the title. I'll compare it to the title column in my models to see if one does better than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1781,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column that combines the text columns into one\n",
    "#I want to test how it does against the title columns\n",
    "true_crime_df['combinedtext'] = true_crime_df['title'] + \" \" + true_crime_df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the same combinedtext column to the my favorite murder df\n",
    "fav_murder_df['combinedtext'] = fav_murder_df['title'] + \" \" + fav_murder_df['selftext']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment Counts Review\n",
    "\n",
    "I took a look at the comment counts because I wanted to see how chatty each subreddits audiences were. I was looking to see that they both had engaged audiences, which they do in this case. Mostly that's a marker to me that the content that's being shared continues to be of interest to the group who is following it. It means the subreddits remain on topic, which is good to know because I want them to be compareable. I'll be able to confirm this when I review each subreddit's top words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>982.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.756619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.105706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_comments\n",
       "count    982.000000\n",
       "mean      13.756619\n",
       "std       30.105706\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        4.000000\n",
       "75%       13.000000\n",
       "max      569.000000"
      ]
     },
     "execution_count": 1870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking a look at how chatty followers of the true crime subreddit are\n",
    "true_crime_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.999001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.519225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_comments\n",
       "count   1001.000000\n",
       "mean       6.999001\n",
       "std       12.519225\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        3.000000\n",
       "75%        7.000000\n",
       "max      142.000000"
      ]
     },
     "execution_count": 1871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and over to ssdgm's subreddit, interesting to note that the variations in max between this one and the other\n",
    "#Curious to see if there is some sort of outlier on the true crime thread that folks were extra chatty on.\n",
    "fav_murder_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dove into the comments more to see what was so exciting over on the True Crime subreddit, since they do have a post that's a bit of an outlier on the comment counts. I will classify that one as a \"celebrity\" citing since it was a picture of someone who had been found not guilty on a high profile murder case.\n",
    "\n",
    "### Most Popular Words\n",
    "\n",
    "Next, I want to check out the frequency counts on words to see what's most popular. I want to see if there are differences in the vocabularly used or if everything overlaps. What I noticed is that while there was much overlapping with targeted words (murder, crime, true), there was also a strong use of podcast specific terminology on the My Favorite Murder subreddit that will be helpful with predicting which one content was posted on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1790,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before diving into cleanup, I want to see what the most popular words used on each subbreddit are\n",
    "#mostly I want to see if podcast terms pop out or if it's all murder and mayhem\n",
    "def count_words(df):\n",
    "    \n",
    "    #instantiating\n",
    "    cvec = CountVectorizer(stop_words = 'english', lowercase=True)\n",
    "\n",
    "    # fitting/transforming\n",
    "    new_cvec = cvec.fit_transform(df)\n",
    "\n",
    "    # converting text to an array\n",
    "    new_cvec = pd.DataFrame(new_cvec.toarray(), columns= cvec.get_feature_names())\n",
    "\n",
    "    # getting the counts\n",
    "    count_words = new_cvec.sum().sort_values(0, ascending=False)\n",
    "    \n",
    "    #returning a df\n",
    "    return count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1791,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling a df of the function for the combined text column (title + selftext) for the true crime df\n",
    "crime_df = pd.DataFrame(count_words(true_crime_df['combinedtext']), columns=[\"Count Combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1792,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count Combined\n",
       "amp                286\n",
       "https              269\n",
       "case               231\n",
       "murder             225\n",
       "com                220"
      ]
     },
     "execution_count": 1792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Interesting, looks like some cleaning up is needed. Not sure what amp is, maybe part of a popular url, \n",
    "#I can see https and com are in the top there too so might be. \n",
    "crime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1793,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling a df of the function for true crime - in this case I'm calling in the title column because I know I \n",
    "#want to test it compared to the combined text column in my models. \n",
    "crime_df = pd.DataFrame(count_words(true_crime_df['title']), columns=[\"Count Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>murder</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count Title\n",
       "murder          113\n",
       "case             91\n",
       "crime            85\n",
       "true             72\n",
       "old              71"
      ]
     },
     "execution_count": 1794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it looks like the title text is cleaner\n",
    "crime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1795,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and now over to the favorite murder df, calling the function with combined text column\n",
    "murder_df = pd.DataFrame(count_words(fav_murder_df['combinedtext']), columns=[\"Count Combined\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Count Combined\n",
       "just                190\n",
       "know                165\n",
       "murder              156\n",
       "episode             154\n",
       "like                154"
      ]
     },
     "execution_count": 1796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing what the top words are, and noting that amp and https don't appear to be as much of issue here\n",
    "#although conversational words just, know, and like are cropping up higher.\n",
    "murder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1797,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the function with the title only text for the favorite murder df\n",
    "murder_df = pd.DataFrame(count_words(fav_murder_df['title']), columns=[\"Count Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mfm</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murder</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karen</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murderino</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count Title\n",
       "mfm                 76\n",
       "murder              63\n",
       "karen               63\n",
       "episode             51\n",
       "murderino           51"
      ]
     },
     "execution_count": 1798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing what the top words from the title column are\n",
    "murder_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Cleanup\n",
    "\n",
    "My approach to data cleanup is to first get rid of duplicates, if there are any. Then combine the dataframes to clean them. I noticed a couple odd characters I wanted to take care of right away. Ampersands being converted to html and tags for new rows (\\n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1799,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the duplicates on the true crime df\n",
    "true_crime_df = true_crime_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(931, 5)"
      ]
     },
     "execution_count": 1800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing how many we lost, which is none in this case\n",
    "true_crime_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1801,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates on the ssdgm df\n",
    "fav_murder_df = fav_murder_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 5)"
      ]
     },
     "execution_count": 1802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seeing how many we lost, which is none in this case\n",
    "fav_murder_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>combinedtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Meme Thread] For all jokes and lighthearted d...</td>\n",
       "      <td>In an effort to clear up some of the clutter a...</td>\n",
       "      <td>TrueCrime</td>\n",
       "      <td>14</td>\n",
       "      <td>[Meme Thread] For all jokes and lighthearted d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A black man in Colorado was detained by cops a...</td>\n",
       "      <td>was</td>\n",
       "      <td>TrueCrime</td>\n",
       "      <td>30</td>\n",
       "      <td>A black man in Colorado was detained by cops a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human remains were found at the home of actor ...</td>\n",
       "      <td>was</td>\n",
       "      <td>TrueCrime</td>\n",
       "      <td>2</td>\n",
       "      <td>Human remains were found at the home of actor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shawn Souza - Dartmouth, MA Police Officer Cha...</td>\n",
       "      <td>was</td>\n",
       "      <td>TrueCrime</td>\n",
       "      <td>1</td>\n",
       "      <td>Shawn Souza - Dartmouth, MA Police Officer Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richey Edwards, of ManicStreetPreachers, disap...</td>\n",
       "      <td>was</td>\n",
       "      <td>TrueCrime</td>\n",
       "      <td>4</td>\n",
       "      <td>Richey Edwards, of ManicStreetPreachers, disap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  [Meme Thread] For all jokes and lighthearted d...   \n",
       "1  A black man in Colorado was detained by cops a...   \n",
       "2  Human remains were found at the home of actor ...   \n",
       "3  Shawn Souza - Dartmouth, MA Police Officer Cha...   \n",
       "4  Richey Edwards, of ManicStreetPreachers, disap...   \n",
       "\n",
       "                                            selftext  subreddit  num_comments  \\\n",
       "0  In an effort to clear up some of the clutter a...  TrueCrime            14   \n",
       "1                                                was  TrueCrime            30   \n",
       "2                                                was  TrueCrime             2   \n",
       "3                                                was  TrueCrime             1   \n",
       "4                                                was  TrueCrime             4   \n",
       "\n",
       "                                        combinedtext  \n",
       "0  [Meme Thread] For all jokes and lighthearted d...  \n",
       "1  A black man in Colorado was detained by cops a...  \n",
       "2  Human remains were found at the home of actor ...  \n",
       "3  Shawn Souza - Dartmouth, MA Police Officer Cha...  \n",
       "4  Richey Edwards, of ManicStreetPreachers, disap...  "
      ]
     },
     "execution_count": 1803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I'm going go ahead and stack the dfs together here to make cleaning easier. \n",
    "df_combined = pd.concat([true_crime_df, fav_murder_df], axis=0)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1804,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first up, I can see that &s have somehow been flipped over to html so let's fix that\n",
    "df_combined['combinedtext'] = df_combined['combinedtext'].map(lambda cell: cell.replace(\"&amp;\",\"&\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1805,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing it in title row too just in case\n",
    "df_combined['title'] = df_combined['title'].map(lambda cell: cell.replace(\"&amp;\",\"&\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1806,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I also noticed some new lines in the code and am pulling that out\n",
    "df_combined['combinedtext'] = df_combined['combinedtext'].map(lambda cell: cell.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing it in title row too just in case\n",
    "df_combined['title'] = df_combined['title'].map(lambda cell: cell.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making subreddit a binary column where true crime = 1 and my favorite murder = 0\n",
    "df_combined['subreddit'] = df_combined['subreddit'].map({'myfavoritemurder': 0, 'TrueCrime': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beautiful Soup, Regex, Lemmatizing, and Stopwords\n",
    "\n",
    "My approach to the following function is that I wanted to strip any random html tags across the text. I also wanted to remove any punctuation and set the text all to lowercase. I realize I can do some of these things in CountVectorizer or TfidfVectorizer, but I wanted these elements cleaned now in order to make my gridsearches run faster.\n",
    "\n",
    "For the text normalization techniques, I tested lemmatizing, Porter and Snowball stemming, and none across all my baseline models. All had similar scores. However, lemmatizing brought my training and test scores closer together, which helped with overfitting. So I went with lemmatizing here.\n",
    "\n",
    "For stopwords, I created a custom list of words based on what I learned when I reviewed most popular words. Murder, true, and crime were in the top words on both subreddits, meaning they would contradict each other and not help with differentiation. I also noticed that any any urls shared in the selftext field had been chopped up into pieces. Https, www, and com. X200b showed up a lot too and I looked into it and found it represents a spacing issue. None of these words will help with predictions so I added them to my stopword list too. Lastly, I noticed some popular conversational language cropping up in the top words that were not words already in the English set (like and know)\n",
    ". So I added them in too. \n",
    "\n",
    "I tested having no stopwords, English, and English plus my custom list of words. The last one worked best across my baseline models for increasing scores as well as helping to fix overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean up the text, edited code from Matt Brems\n",
    "def posts_clean(text):\n",
    "    #removing any html\n",
    "    review_text = BeautifulSoup(text).get_text()\n",
    "    \n",
    "    # removing non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # converting to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    #lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "        \n",
    "    # converting stopwords to set\n",
    "    stop_words = stopwords.words('english')\n",
    "    new_stops = ['www', 'https', 'com', 'x200b', 'like', 'know', 'murder', 'crime', 'true']\n",
    "    stop_words.extend(new_stops)\n",
    "    stops = set(stop_words)\n",
    "    \n",
    "    # removing stop words\n",
    "    meaningful_words = [w for w in lem_words if not w in stops]\n",
    "    \n",
    "    # joining the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing an empty list to hold the clean posts\n",
    "clean_posts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up a for loop to iterate through the column\n",
    "j = 0\n",
    "for posts_update in df_combined['combinedtext']:\n",
    "    clean_posts.append(posts_clean(posts_update)) \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling the list values into a column\n",
    "df_combined['clean_posts'] = clean_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing an empty list to hold the clean titles\n",
    "clean_titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up a for loop to iterate through the column\n",
    "j = 0\n",
    "for posts_update in df_combined['title']:\n",
    "    clean_titles.append(posts_clean(posts_update))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1879,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling the list values into a column\n",
    "df_combined['clean_titles'] = clean_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1880,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>combinedtext</th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>clean_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Meme Thread] For all jokes and lighthearted d...</td>\n",
       "      <td>In an effort to clear up some of the clutter a...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>[Meme Thread] For all jokes and lighthearted d...</td>\n",
       "      <td>meme thread joke lighthearted discussion effor...</td>\n",
       "      <td>meme thread joke lighthearted discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  [Meme Thread] For all jokes and lighthearted d...   \n",
       "\n",
       "                                            selftext  subreddit  num_comments  \\\n",
       "0  In an effort to clear up some of the clutter a...          1            14   \n",
       "\n",
       "                                        combinedtext  \\\n",
       "0  [Meme Thread] For all jokes and lighthearted d...   \n",
       "\n",
       "                                         clean_posts  \\\n",
       "0  meme thread joke lighthearted discussion effor...   \n",
       "\n",
       "                               clean_titles  \n",
       "0  meme thread joke lighthearted discussion  "
      ]
     },
     "execution_count": 1880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to make sure everything updated correctly\n",
    "df_combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1817,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm saving a clean version of the dataframe to use in a supplement notebook (Modeling_Supplement.ipynb)\n",
    "#The supplement notebook includes testing models, while the best model is featured in the next section.\n",
    "df_combined.to_csv('./datasets/clean_df_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "My approach for modeling was to set up 4 variations of pipelines for three model types: Logistic Regression, Naive Bayes, and Support Vector Machine. I only included the best model in this notebook. Please see Modeling_Supplement.ipynb for a look at the other models that were tested.\n",
    "\n",
    "I set up four variations because I wanted to test different options for X (title vs. title + subtext) and I wanted to test two vectorizers (CountVectorizer and TfidfVectorizer). I set each of these models at their default settings to run tests on text normalization and stopwords. Once I settled on lemmatization and stopwords of English plus a custom list as my best performing options, I moved on to testing parameters. \n",
    "\n",
    "For parameters, I took a step by step approach, layering in new ranges of parameters for the gridsearch to test, including max features, n-grams, and max and min document frequencies. I also tested model specific options including penalties and the inverse of regularization strength. What I found though was that adding penalties made my scores worse and my models more overfit. So I backed up and scaled down on the options and ended up honing in on max features. I started dropping the max features and found that it helped with overfitting and with better scores. However, I had to make sure to not go too low, else the range between train and test scores would increase again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.518116\n",
       "1    0.481884\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 1818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the baseline accuracy. Our goal here is to do better than 51.7%, which is the majority of the sample.\n",
    "df_combined['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model\n",
    "\n",
    "My best performing model was Naive Bayes Multinomial. The X was the title combined with selftext. The text normalizer was lemmatization and the stopwords were English plus a custom list of words. TifdVectorizer was the vectorizer used with max features of 738.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_posts', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1820,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_posts']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1822,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()), \n",
    "    ('nb', MultinomialNB()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1857,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8184955141476881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': 738}"
      ]
     },
     "execution_count": 1857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [738],\n",
    "\n",
    "}\n",
    "best = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "best.fit(X_train, y_train); \n",
    "print(best.best_score_)\n",
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723257418909592"
      ]
     },
     "execution_count": 1858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "best.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612836438923396"
      ]
     },
     "execution_count": 1859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\"><strong>MODEL BREAKDOWN</strong></p>\n",
    "\n",
    "| Model | Train Score | Test Score | Best Cross-Val Score | X | Text Normalization\n",
    "|:----------:|:-------------:|:------:|:------:| :------:| :------:|\n",
    "| Logistic Regression 1 | 0.9586 | 0.8282 | 0.7964 | combined text | CountVectorizer | \n",
    "| Logistic Regression 2 | 0.9296 | 0.8178 | 0.7778 | title | CountVectorizer |  \n",
    "| Logistic Regression 3 | 0.9165 | 0.8654 | 0.8213 | combined text | TfidfVectorizer |\n",
    "| Logistic Regression 4 | 0.9068 | 0.8157 | 0.7888 | title | TfidfVectorizer |\n",
    "| Naive Bayes 1 | 0.8578 | 0.8219 | 0.7985 | combined text | CountVectorizer | \n",
    "| Naive Bayes 2 | 0.8730 | 0.8116 | 0.7867 | title | CountVectorizer |  \n",
    "| Naive Bayes 3 | 0.8723 | 0.8613 | 0.8185 | combined text | TfidfVectorizer |\n",
    "| Naive Bayes 4 | 0.8937 | 0.8219 | 0.7902 | title | TfidfVectorizer |\n",
    "| Support Vector Machine 1 | 0.6273 | 0.6398 | 0.5769 | combined text | CountVectorizer | \n",
    "| Support Vector Machine 2 | 0.6273 | 0.6398 | 0.5769 | title | CountVectorizer |  \n",
    "| Support Vector Machine 3 | 0.7129 | 0.7371 | 0.6929 | combined text | TfidfVectorizer |\n",
    "| Support Vector Machine 4 | 0.5183 | 0.5176 | 0.5183 | title | TfidfVectorizer |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My baseline accuracy is 51.8% and my goal was to beat that score. You can see the breakdown of the model scores in the grid above. All models except one beat the baseline score. One of my Support Vector Machine models did not beat it. This model used the title as the X and used TfidVectorizer as its vectorizer. The train score matched the 51.8% while the test score was lower at 51.7%. The Support Vector Machine models overall were my worst performing models. While the train and test scores were about the same for each model (so they weren't overfit), they were the lowest accuracy scores overall. \n",
    "\n",
    "The Logistic Regression models had higher scores overall, however each model was significantly overfit. The test scores ranged from 81.6 - 86.6%, while the train scores ranged from 90.7 - 95.9%. The Naive Bayes models were similar scores, however they were less overfit, including one model that is close enough in range between train and test scores to no longer be considered overfit. The test scores ranged from 81.2 - 86.1% and the train scores ranged from 85.5 - 89.4%. The best performing model was a Naive Bayes model with a test score of 86.1% and a train score of 87.2%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confustion Matrix\n",
    "\n",
    "I wanted to take a look at how many posts were actually currected accurately with my best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1826,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting predictions of the best model\n",
    "predictions = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[223,  27],\n",
       "       [ 41, 192]])"
      ]
     },
     "execution_count": 1827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating a confusion matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1828,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unraveling the matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 223\n",
      "False Positives: 27\n",
      "False Negatives: 41\n",
      "True Positives: 192\n"
     ]
    }
   ],
   "source": [
    "#printing out the values\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model correctly predicted 415 posts, while it incorrectly predicted 68 posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My best model was able to predict placement of content on the True Crime subreddit vs. the My Favorite Murder subreddit with an accuracy of 86%. That's why I would recommend the Naive Bayes model as the one to use here. However, the caveat I would add is that Reddit content changes daily. What that means is that accuracy can and will change based on what content is available on any particular day. The model will need to be adjusted accordingly with updating what stopwords are included and fine tuning the max feature value. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
