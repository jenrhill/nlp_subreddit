{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Subreddit Classification - Modeling Supplement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script can only be run after you run the notebook NLP_Subreddit_Classificiation.ipynb. Clean files were saved in that process to be used here. Here is where you can find a breakdown of each model I ran through for testing.\n",
    "\n",
    "### Contents:\n",
    "- [Imports](#Imports)\n",
    "- [Modeling](#Modeling)\n",
    "  * [Logistic Regression Model 1](#Logistic-Regression-Model-1) - combined text (title + selftext) for X and CountVectorizer\n",
    "  * [Logistic Regression Model 2](#Logistic-Regression-Model-2) - title for X and CountVectorizer\n",
    "  * [Logistic Regression Model 3](#Logistic-Regression-Model-3) - combined text for X and TfidfVectorizer\n",
    "  * [Logistic Regression Model 4](#Logistic-Regression-Model-4) - title for X and TfidfVectorizer\n",
    "  * [Naive Bayes Model 1](#Naive-Bayes-Model-1) - combined text for X and CountVectorizer  \n",
    "  * [Naive Bayes Model 2](#Naive-Bayes-Model-2) - title for X and CountVectorizer\n",
    "  * [Naive Bayes Model 4](#Naive-Bayes-Model-4) - title for X and TfidfVectorizer\n",
    "  * [Support Vector Machine Model 1](#Support-Vector-Machine-Model-1) - combined text for X and CountVectorizer\n",
    "  * [Support Vector Machine Model 2](#Support-Vector-Machine-Model-2) - title for X and CountVectorizer\n",
    "  * [Support Vector Machine Model 3](#Support-Vector-Machine-Model-3) - combined text for X and TfidfVectorizer\n",
    "  * [Support Vector Machine Model 4](#Support-Vector-Machine-Model-4) - title for X and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing in the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing warning to turn off future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the cleaned file\n",
    "df_combined = pd.read_csv('./datasets/clean_df_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the saved file, pulled in 10 Nans. Converting them back to blank cells\n",
    "df_combined['clean_titles'] = df_combined['clean_titles'].fillna(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.518116\n",
       "1    0.481884\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the baseline accuracy. Our goal here is to do better than 51.7%, which is the majority of the sample.\n",
    "df_combined['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Reg Model 1\n",
    "\n",
    "This model uses combined text (title + selftext) for X and uses CountVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_posts', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_posts']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('lr', LogisticRegression()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964113181504486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1000}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1000]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9585921325051759"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302277432712215"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Reg Model 2\n",
    "\n",
    "This model uses titles for X and uses CountVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_titles', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_titles']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('lr', LogisticRegression()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1000}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1000]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296066252587992"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8178053830227743"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Reg Model 3\n",
    "\n",
    "This model uses combined (title & selftext) for X and uses TfidVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_posts', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_posts']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()), \n",
    "    ('lr', LogisticRegression()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821256038647343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': 1000}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [1000]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9164941338854382"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865424430641822"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Reg Model 4\n",
    "\n",
    "This model uses combined titles for X and uses TfidfVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_titles', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_titles']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()), \n",
    "    ('lr', LogisticRegression()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7888198757763976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': 1000}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [1000],\n",
    "\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906832298136646"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157349896480331"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model 1\n",
    "\n",
    "This model uses combined text (title + selftext) for X and uses CountVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_posts', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_posts']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('nb', MultinomialNB()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7984817115251898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1000}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1000]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8578329882677709"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219461697722568"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model 2\n",
    "\n",
    "This model uses titles for X and uses CountVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_titles', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_titles']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('nb', MultinomialNB()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7867494824016563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 1000}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1000]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873015873015873"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115942028985508"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on Naive Bayes Model 3. This was the best performing model and can be seen in the main notebook Project_3_Main_File.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model 4\n",
    "\n",
    "This model uses combined titles for X and uses TfidfVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_titles', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_titles']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790200138026225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': 1000}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()), \n",
    "    ('nb', MultinomialNB()) \n",
    "])\n",
    "\n",
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [1000]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.893719806763285"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219461697722568"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model 1\n",
    "\n",
    "This model uses combined text (title + selftext) for X and uses CountVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_titles', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_titles']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5769496204278813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 200}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),  \n",
    "    ('svm', svm.SVC(gamma = 'auto')) \n",
    "])\n",
    "\n",
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [200]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273291925465838"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639751552795031"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model 2\n",
    "\n",
    "This model uses titles for X and uses CountVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_titles', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_titles']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5769496204278813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 200}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),  \n",
    "    ('svm', svm.SVC(gamma = 'auto')) \n",
    "])\n",
    "\n",
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [200]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273291925465838"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639751552795031"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model 3\n",
    "\n",
    "This model uses combined (title & selftext) for X and uses TfidVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_posts', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_posts']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6928916494133885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': 50}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),  \n",
    "    ('svm', svm.SVC(gamma = 'auto')) \n",
    "])\n",
    "\n",
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [50]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7129054520358868"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7370600414078675"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model 4\n",
    "\n",
    "This model uses combined titles for X and uses TfidfVectorizer.\n",
    "\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping down to just the columns I want to use\n",
    "df_crop = df_combined[['clean_titles', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting X and y\n",
    "X = df_crop['clean_titles']\n",
    "y = df_crop['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5182884748102139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': 1000}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the pipeline order\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),  \n",
    "    ('svm', svm.SVC(gamma = 'auto')) \n",
    "])\n",
    "\n",
    "#setting up the pipe parameters\n",
    "pipe_params = {\n",
    "    'tvec__max_features': [1000]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train); \n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5182884748102139"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train score\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5175983436853002"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "gs.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
